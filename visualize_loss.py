#!/usr/bin/env python3
"""
ì—¬ëŸ¬ ì‹¤í—˜ì˜ ë¡œìŠ¤ ì»¤ë¸Œë¥¼ ë¹„êµ ì‹œê°í™”í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    # ëª¨ë“  ì‹¤í—˜ CSV ë¹„êµ
    python visualize_loss.py experiments/*/training_log.csv
    
    # ì¶œë ¥ íŒŒì¼ ì§€ì •
    python visualize_loss.py --output comparison.png experiments/*/training_log.csv
    
    # ìš”ì•½ í…Œì´ë¸”ë„ ì €ì¥
    python visualize_loss.py -o comparison.png -s summary.csv experiments/*/training_log.csv
    
    # Xì¶•ì„ epochìœ¼ë¡œ í‘œì‹œ
    python visualize_loss.py --by_epoch experiments/*/training_log.csv
"""

import argparse
import json
import re
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd


# í•œê¸€ í°íŠ¸ ì„¤ì • (ì„ íƒì )
try:
    import platform
    if platform.system() == 'Windows':
        plt.rcParams['font.family'] = 'Malgun Gothic'
    elif platform.system() == 'Darwin':  # macOS
        plt.rcParams['font.family'] = 'AppleGothic'
    else:  # Linux
        plt.rcParams['font.family'] = 'NanumGothic'
    plt.rcParams['axes.unicode_minus'] = False
except:
    pass


def load_csv_with_metadata(csv_path: str) -> tuple[pd.DataFrame, dict]:
    """CSV íŒŒì¼ê³¼ ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
    metadata = {}
    
    with open(csv_path, 'r', encoding='utf-8') as f:
        first_line = f.readline()
        if first_line.startswith('# experiment_info:'):
            json_str = first_line.replace('# experiment_info:', '').strip()
            try:
                metadata = json.loads(json_str)
            except json.JSONDecodeError:
                pass
    
    df = pd.read_csv(csv_path, comment='#')
    return df, metadata


def extract_rank_from_path(csv_path: str) -> int:
    """íŒŒì¼ ê²½ë¡œì—ì„œ rank ì¶”ì¶œ"""
    match = re.search(r'_r(\d+)_', csv_path)
    if match:
        return int(match.group(1))
    return 0


def extract_model_from_path(csv_path: str) -> str:
    """íŒŒì¼ ê²½ë¡œì—ì„œ ëª¨ë¸ëª… ì¶”ì¶œ"""
    path = Path(csv_path)
    parent_name = path.parent.name
    # ëª¨ë¸ëª… ì¶”ì¶œ ì‹œë„ (ì²« ë²ˆì§¸ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ êµ¬ë¶„ëœ ë¶€ë¶„ë“¤)
    parts = parent_name.split('_')
    # rìˆ«ì íŒ¨í„´ì´ ë‚˜ì˜¤ê¸° ì „ê¹Œì§€ê°€ ëª¨ë¸ëª…
    model_parts = []
    for part in parts:
        if re.match(r'^r\d+$', part):
            break
        model_parts.append(part)
    return '_'.join(model_parts) if model_parts else parent_name


def plot_loss_curves(csv_files: list[str], output_path: str = None, 
                     by_epoch: bool = False, title: str = None):
    """ì—¬ëŸ¬ ì‹¤í—˜ì˜ ë¡œìŠ¤ ì»¤ë¸Œ ì‹œê°í™”"""
    
    if not csv_files:
        print("âŒ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # rank ìˆœì„œë¡œ ì •ë ¬
    csv_files_sorted = sorted(csv_files, key=extract_rank_from_path)
    
    # ìƒ‰ìƒ íŒ”ë ˆíŠ¸
    colors = plt.cm.tab10(np.linspace(0, 1, max(len(csv_files_sorted), 10)))
    
    model_name = ""
    
    for idx, csv_path in enumerate(csv_files_sorted):
        try:
            df, metadata = load_csv_with_metadata(csv_path)
        except Exception as e:
            print(f"âš ï¸ {csv_path} ë¡œë“œ ì‹¤íŒ¨: {e}")
            continue
        
        # ë ˆì´ë¸” ìƒì„±
        if metadata:
            label = f"r{metadata.get('rank', '?')} (Î±={metadata.get('alpha', '?')})"
            if not model_name:
                model_name = metadata.get('model', '').split('/')[-1]
        else:
            rank = extract_rank_from_path(csv_path)
            label = f"r{rank}" if rank else Path(csv_path).stem
            if not model_name:
                model_name = extract_model_from_path(csv_path)
        
        x_col = 'epoch' if by_epoch else 'step'
        
        # Train Loss
        train_df = df[df['train_loss'].notna() & (df['train_loss'] != '')]
        if not train_df.empty:
            try:
                axes[0].plot(
                    train_df[x_col].astype(float), 
                    train_df['train_loss'].astype(float),
                    label=label, color=colors[idx % len(colors)], alpha=0.8, linewidth=1.5
                )
            except Exception as e:
                print(f"âš ï¸ Train loss í”Œë¡¯ ì‹¤íŒ¨ ({csv_path}): {e}")
        
        # Eval Loss
        eval_df = df[df['eval_loss'].notna() & (df['eval_loss'] != '')]
        if not eval_df.empty:
            try:
                axes[1].plot(
                    eval_df[x_col].astype(float), 
                    eval_df['eval_loss'].astype(float),
                    label=label, color=colors[idx % len(colors)], 
                    marker='o', markersize=3, linewidth=1.5
                )
            except Exception as e:
                print(f"âš ï¸ Eval loss í”Œë¡¯ ì‹¤íŒ¨ ({csv_path}): {e}")
    
    # ìŠ¤íƒ€ì¼ë§
    x_label = 'Epoch' if by_epoch else 'Step'
    
    axes[0].set_xlabel(x_label, fontsize=11)
    axes[0].set_ylabel('Train Loss', fontsize=11)
    axes[0].set_title('Training Loss by LoRA Rank', fontsize=12, fontweight='bold')
    axes[0].legend(loc='upper right')
    axes[0].grid(True, alpha=0.3)
    
    axes[1].set_xlabel(x_label, fontsize=11)
    axes[1].set_ylabel('Eval Loss', fontsize=11)
    axes[1].set_title('Evaluation Loss by LoRA Rank', fontsize=12, fontweight='bold')
    axes[1].legend(loc='upper right')
    axes[1].grid(True, alpha=0.3)
    
    # ì „ì²´ íƒ€ì´í‹€
    if title:
        fig.suptitle(title, fontsize=14, fontweight='bold')
    elif model_name:
        fig.suptitle(f'LoRA Rank Comparison - {model_name}', fontsize=14, fontweight='bold')
    else:
        fig.suptitle('LoRA Rank Comparison', fontsize=14, fontweight='bold')
    
    plt.tight_layout()
    
    if output_path:
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        print(f"âœ… ê·¸ë˜í”„ ì €ì¥: {output_path}")
    
    plt.show()


def plot_final_loss_comparison(csv_files: list[str], output_path: str = None):
    """ìµœì¢… ë¡œìŠ¤ ê°’ì„ ë§‰ëŒ€ ê·¸ë˜í”„ë¡œ ë¹„êµ"""
    
    results = []
    
    for csv_path in csv_files:
        try:
            df, metadata = load_csv_with_metadata(csv_path)
            
            train_losses = df[df['train_loss'].notna() & (df['train_loss'] != '')]['train_loss'].astype(float)
            eval_losses = df[df['eval_loss'].notna() & (df['eval_loss'] != '')]['eval_loss'].astype(float)
            
            rank = metadata.get('rank', extract_rank_from_path(csv_path))
            
            results.append({
                'rank': rank,
                'final_train_loss': train_losses.iloc[-1] if len(train_losses) > 0 else None,
                'min_eval_loss': eval_losses.min() if len(eval_losses) > 0 else None,
            })
        except Exception as e:
            print(f"âš ï¸ {csv_path} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    
    if not results:
        print("âŒ ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    df_results = pd.DataFrame(results).sort_values('rank')
    
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))
    
    x = range(len(df_results))
    width = 0.6
    
    # Final Train Loss
    axes[0].bar(x, df_results['final_train_loss'], width, color='steelblue', alpha=0.8)
    axes[0].set_xlabel('LoRA Rank', fontsize=11)
    axes[0].set_ylabel('Final Train Loss', fontsize=11)
    axes[0].set_title('Final Training Loss by Rank', fontsize=12, fontweight='bold')
    axes[0].set_xticks(x)
    axes[0].set_xticklabels([f"r{r}" for r in df_results['rank']])
    axes[0].grid(True, alpha=0.3, axis='y')
    
    # Min Eval Loss
    axes[1].bar(x, df_results['min_eval_loss'], width, color='coral', alpha=0.8)
    axes[1].set_xlabel('LoRA Rank', fontsize=11)
    axes[1].set_ylabel('Min Eval Loss', fontsize=11)
    axes[1].set_title('Minimum Evaluation Loss by Rank', fontsize=12, fontweight='bold')
    axes[1].set_xticks(x)
    axes[1].set_xticklabels([f"r{r}" for r in df_results['rank']])
    axes[1].grid(True, alpha=0.3, axis='y')
    
    plt.tight_layout()
    
    if output_path:
        bar_output = output_path.replace('.png', '_bar.png').replace('.jpg', '_bar.jpg')
        plt.savefig(bar_output, dpi=150, bbox_inches='tight')
        print(f"âœ… ë§‰ëŒ€ ê·¸ë˜í”„ ì €ì¥: {bar_output}")
    
    plt.show()


def create_summary_table(csv_files: list[str], output_path: str = None) -> pd.DataFrame:
    """ì‹¤í—˜ ê²°ê³¼ ìš”ì•½ í…Œì´ë¸” ìƒì„±"""
    
    results = []
    
    for csv_path in csv_files:
        try:
            df, metadata = load_csv_with_metadata(csv_path)
            
            # ìµœì¢… ë¡œìŠ¤ ê°’ ì¶”ì¶œ
            train_losses = df[df['train_loss'].notna() & (df['train_loss'] != '')]['train_loss'].astype(float)
            eval_losses = df[df['eval_loss'].notna() & (df['eval_loss'] != '')]['eval_loss'].astype(float)
            
            result = {
                'model': metadata.get('model', '').split('/')[-1] if metadata else extract_model_from_path(csv_path),
                'rank': metadata.get('rank', extract_rank_from_path(csv_path)),
                'alpha': metadata.get('alpha', ''),
                'lr': metadata.get('learning_rate', ''),
                'epochs': metadata.get('epochs', ''),
                'final_train_loss': round(train_losses.iloc[-1], 4) if len(train_losses) > 0 else None,
                'min_train_loss': round(train_losses.min(), 4) if len(train_losses) > 0 else None,
                'final_eval_loss': round(eval_losses.iloc[-1], 4) if len(eval_losses) > 0 else None,
                'min_eval_loss': round(eval_losses.min(), 4) if len(eval_losses) > 0 else None,
                'csv_path': csv_path,
            }
            results.append(result)
        except Exception as e:
            print(f"âš ï¸ {csv_path} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    
    if not results:
        print("âŒ ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()
    
    summary_df = pd.DataFrame(results)
    summary_df = summary_df.sort_values('rank')
    
    # ì¶œë ¥ìš© ì»¬ëŸ¼ ì„ íƒ (csv_path ì œì™¸)
    display_cols = ['model', 'rank', 'alpha', 'lr', 'epochs', 
                    'final_train_loss', 'min_train_loss', 'final_eval_loss', 'min_eval_loss']
    
    print("\n" + "=" * 100)
    print("ğŸ“Š ì‹¤í—˜ ê²°ê³¼ ìš”ì•½")
    print("=" * 100)
    print(summary_df[display_cols].to_string(index=False))
    print("=" * 100)
    
    if output_path:
        summary_df.to_csv(output_path, index=False)
        print(f"\nâœ… ìš”ì•½ í…Œì´ë¸” ì €ì¥: {output_path}")
    
    return summary_df


def main():
    parser = argparse.ArgumentParser(
        description="LoRA ì‹¤í—˜ ë¡œìŠ¤ ì»¤ë¸Œ ì‹œê°í™”",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
    python visualize_loss.py experiments/*/training_log.csv
    python visualize_loss.py --output comparison.png experiments/*/training_log.csv
    python visualize_loss.py -o comparison.png -s summary.csv experiments/*/training_log.csv
    python visualize_loss.py --by_epoch experiments/*/training_log.csv
        """
    )
    parser.add_argument("csv_files", nargs="+", help="CSV ë¡œê·¸ íŒŒì¼ë“¤")
    parser.add_argument("--output", "-o", type=str, default=None, help="ì¶œë ¥ ì´ë¯¸ì§€ ê²½ë¡œ")
    parser.add_argument("--by_epoch", action="store_true", help="Xì¶•ì„ epochìœ¼ë¡œ í‘œì‹œ")
    parser.add_argument("--summary", "-s", type=str, default=None, help="ìš”ì•½ CSV ì €ì¥ ê²½ë¡œ")
    parser.add_argument("--title", "-t", type=str, default=None, help="ê·¸ë˜í”„ íƒ€ì´í‹€")
    parser.add_argument("--bar", action="store_true", help="ìµœì¢… ë¡œìŠ¤ ë§‰ëŒ€ ê·¸ë˜í”„ë„ í‘œì‹œ")
    
    args = parser.parse_args()
    
    print(f"\nğŸ“ {len(args.csv_files)}ê°œ CSV íŒŒì¼ ë¡œë“œ ì¤‘...")
    for f in args.csv_files:
        print(f"   - {f}")
    
    # ìš”ì•½ í…Œì´ë¸” ìƒì„±
    create_summary_table(args.csv_files, args.summary)
    
    # ë¡œìŠ¤ ì»¤ë¸Œ ì‹œê°í™”
    plot_loss_curves(args.csv_files, args.output, by_epoch=args.by_epoch, title=args.title)
    
    # ë§‰ëŒ€ ê·¸ë˜í”„ (ì„ íƒì )
    if args.bar:
        plot_final_loss_comparison(args.csv_files, args.output)


if __name__ == "__main__":
    main()

